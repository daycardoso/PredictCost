{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daycardoso/PredictCost/blob/main/PredictCostDecisionTreeRegressor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trabalho CMP263 - Aprendizagem de Máquina - INF/UFRGS\n",
        "\n",
        "## Modelo 1 - Decision tree sem poda\n",
        "\n",
        "As árvores de decisão são conhecidas por possuírem um baixo viés, ao mesmo tempo em que apresentam alta variância.\n",
        "Isto é, o método é capaz de modelar fronteiras de decisão bastante complexas, o que, por um lado, é positivo, mas torna o algoritmo bastante suscetível a ruído ou a padrões nos dados de treino que não generalizam para instâncias de teste.\n",
        "Por isso, técnicas de poda são fundamentais para o uso efetivo do modelo em dados novos.\n",
        "\n"
      ],
      "metadata": {
        "id": "E650rvooE65t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objetivos da Atividade\n",
        "* Analisar os impactos da característica de **variância** nas árvores de decisão.\n",
        "* Analisar o efeito da **poda** em árvores de decisão.\n"
      ],
      "metadata": {
        "id": "bzW8jdj7Jgp0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregamento dos Dados\n"
      ],
      "metadata": {
        "id": "owi-J_whK4IS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtenção e análise dos dados\n",
        "O código abaixo carrega o dataset do kaggle e mostra algumas informações básicas sobre os dados"
      ],
      "metadata": {
        "id": "SqJsx9OITVn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gqs1uPW95__c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# import glob\n",
        "\n",
        "# arquivos = glob.glob('/content/drive/MyDrive/Trabalho ML Mestrado 01-2025/*.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "rfTSbcxF_Ei6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dfs = [pd.read_csv(f) for f in arquivos]\n",
        "# df_unificado = pd.concat(dfs, axis=0, ignore_index=True)\n",
        "# df_unificado.head()"
      ],
      "metadata": {
        "id": "ACuMo2cjIP7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excluir a coluna type\n",
        "# df_unificado = df_unificado.drop('type', axis=1)\n",
        "# df_unificado.head()"
      ],
      "metadata": {
        "id": "TyjiqnDQDhTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Garantir que não a duplicata de instancias evitando sobreposição entre os dados de treinamento e teste\n",
        "# df_unificado = df_unificado.drop_duplicates().reset_index(drop=True)\n",
        "# df_unificado.head(-50)"
      ],
      "metadata": {
        "id": "w6WTOZinHWWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar o dataset completo, sem duplicatas\n",
        "# df_unificado.to_csv('/content/drive/MyDrive/Trabalho ML Mestrado 01-2025/df_unificado.csv', index=False)"
      ],
      "metadata": {
        "id": "P5TiN0ACFnPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o datset unificado\n",
        "df_unificado = pd.read_csv('/content/drive/MyDrive/Trabalho ML Mestrado 01-2025/df_unificado.csv')"
      ],
      "metadata": {
        "id": "zGi6kt1-Hiai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# matriz contendo os atributos\n",
        "X = df_unificado.iloc[:, :-1].values\n",
        "\n",
        "# vetor contendo o custo, ou seja, a ultima coluna\n",
        "y = df_unificado.iloc[:, -1].values\n",
        "\n",
        "# nome de cada atributo\n",
        "feature_names = df_unificado.columns[:-1]\n",
        "\n",
        "# nome de cada classe\n",
        "target_names = df_unificado.columns[-1]\n",
        "\n",
        "print(f\"Dimensões de X: {X.shape}\\n\")\n",
        "print(f\"Dimensões de y: {y.shape}\\n\")\n",
        "print(f\"Nomes dos atributos: {feature_names}\\n\")\n",
        "print(f\"Nomes das classes: {target_names}\")"
      ],
      "metadata": {
        "id": "0wQUO3NaD_Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, RepeatedKFold, cross_validate\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import joblib\n",
        "\n",
        "# 1) Cria um hold-out antes de qualquer CV\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "l_sS3CC5nvLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    ('regressor', DecisionTreeRegressor(random_state=42))\n",
        "])\n"
      ],
      "metadata": {
        "id": "vmN6v5YjKpBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RepeatedKFold\n",
        "\n",
        "# 5×5 CV repetida: balanceia viés x variância na estimação\n",
        "cv = RepeatedKFold(n_splits=5, n_repeats=5, random_state=42)\n"
      ],
      "metadata": {
        "id": "QqqgtLqEIpWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "scoring = {\n",
        "    'R2': 'r2',\n",
        "    'MSE': 'neg_mean_squared_error',\n",
        "    'MAE': 'neg_mean_absolute_error',\n",
        "    'MAPE': 'neg_mean_absolute_percentage_error',\n",
        "    'MedAE': 'neg_median_absolute_error',\n",
        "    'MaxE': 'max_error',\n",
        "    'EVS': 'explained_variance',\n",
        "}\n",
        "\n",
        "cv_results = cross_validate(\n",
        "    pipeline, X_train_full, y_train_full,\n",
        "    cv=cv, scoring=scoring, return_train_score=True, n_jobs=-1\n",
        ")"
      ],
      "metadata": {
        "id": "aBPNGZv-KV3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Treinar o modelo\n",
        "# # pipeline.fit(X_train_full, y_train_full)\n",
        "# modelo = pipeline.fit(X_train_full, y_train_full)"
      ],
      "metadata": {
        "id": "LWeJ5i_3oKrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Gera predições no hold-out\n",
        "# y_pred = pipeline.predict(X_test)"
      ],
      "metadata": {
        "id": "X7ObbwraoPA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 6) Salva TUDO num dict\n",
        "# full_results = {\n",
        "#     'pipeline': pipeline,\n",
        "#     'X_test':   X_test,\n",
        "#     'y_test':   y_test,\n",
        "#     'y_pred':   y_pred,\n",
        "#     'cv_results': cv_results,\n",
        "#     'feature_names': feature_names\n",
        "# }\n",
        "# joblib.dump(full_results, '/content/drive/MyDrive/Trabalho ML Mestrado 01-2025/decision_tree_regressor_full_results.pkl')"
      ],
      "metadata": {
        "id": "_XbBPvSsoRZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import joblib\n",
        "# # Carregar o modelo\n",
        "# pipeline = joblib.load('/content/drive/MyDrive/Trabalho ML Mestrado 01-2025/modelo_joblib.pkl')\n"
      ],
      "metadata": {
        "id": "I66pLt1oE-cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    r2_score,\n",
        "    mean_squared_error,\n",
        "    mean_absolute_error,\n",
        "    mean_absolute_percentage_error,\n",
        "    median_absolute_error,\n",
        "    max_error,\n",
        "    explained_variance_score\n",
        ")\n",
        "from IPython.display import display\n",
        "\n",
        "# Carregar resultados\n",
        "res = joblib.load('/content/drive/MyDrive/Trabalho ML Mestrado 01-2025/decision_tree_regressor_full_results.pkl')\n",
        "model         = res['pipeline']\n",
        "X_test        = res['X_test']\n",
        "y_true        = res['y_test']\n",
        "y_pred        = res.get('y_pred', model.predict(X_test))\n",
        "feature_names = res.get('feature_names', getattr(X_test, 'columns', None))\n",
        "\n",
        "# 1) Exibir métricas em tabela\n",
        "metrics = {\n",
        "    'R² Score'           : r2_score(y_true, y_pred),\n",
        "    'MSE'                 : mean_squared_error(y_true, y_pred),\n",
        "    'MAE'                 : mean_absolute_error(y_true, y_pred),\n",
        "    'MAPE'                : mean_absolute_percentage_error(y_true, y_pred),\n",
        "    'Median AE'           : median_absolute_error(y_true, y_pred),\n",
        "    'Max Error'           : max_error(y_true, y_pred),\n",
        "    'Explained Variance'  : explained_variance_score(y_true, y_pred)\n",
        "}\n",
        "df_metrics = pd.DataFrame.from_dict(metrics, orient='index', columns=['Valor']).round(4)\n",
        "display(df_metrics)\n",
        "\n",
        "# 2) Scatter Real vs Predito\n",
        "plt.figure()\n",
        "plt.scatter(y_true, y_pred)\n",
        "min_val, max_val = np.min([y_true.min(), y_pred.min()]), np.max([y_true.max(), y_pred.max()])\n",
        "plt.plot([min_val, max_val], [min_val, max_val])\n",
        "plt.xlabel('Valor Real')\n",
        "plt.ylabel('Valor Predito')\n",
        "plt.title('Real vs Predito')\n",
        "plt.show()\n",
        "\n",
        "# 3) Histograma de resíduos\n",
        "residuals = y_true - y_pred\n",
        "plt.figure()\n",
        "plt.hist(residuals, bins=50)\n",
        "plt.xlabel('Resíduo (Real - Predito)')\n",
        "plt.title('Histograma de Resíduos')\n",
        "plt.show()\n",
        "\n",
        "# 4) Boxplot de resíduos por quartil\n",
        "df_r = pd.DataFrame({'Real': y_true, 'Resíduo': residuals})\n",
        "df_r['Quartil'] = pd.qcut(df_r['Real'], 4, labels=[1, 2, 3, 4])\n",
        "groups = [df_r[df_r['Quartil'] == q]['Resíduo'] for q in sorted(df_r['Quartil'].unique())]\n",
        "plt.figure()\n",
        "plt.boxplot(groups, labels=sorted(df_r['Quartil'].unique()))\n",
        "plt.xlabel('Quartil de Valor Real')\n",
        "plt.ylabel('Resíduo')\n",
        "plt.title('Boxplot de Resíduos por Quartil')\n",
        "plt.show()\n",
        "\n",
        "# 5) Importância das features (se aplicável)\n",
        "if hasattr(model, 'feature_importances_') and feature_names is not None:\n",
        "    fi = pd.Series(model.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    fi.plot(kind='bar')\n",
        "    plt.ylabel('Importância')\n",
        "    plt.title('Importância das Features')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "KJzfeCmXFTJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  poucas previsões com grandes desvios, possiveis outliers\n",
        "\n"
      ],
      "metadata": {
        "id": "LEGN0nEOvzTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Suponha que você já tenha:\n",
        "# y_true: valores reais\n",
        "# y_pred: valores preditos\n",
        "# X_test: features de teste (idealmente como DataFrame)\n",
        "\n",
        "# Garante que y_test seja um array 1D\n",
        "y_true_array = np.ravel(y_true)\n",
        "\n",
        "# Cria DataFrame com todas as informações relevantes\n",
        "df_erros = pd.DataFrame({\n",
        "    'Valor Real': y_true_array,\n",
        "    'Valor Predito': y_pred,\n",
        "    'Erro Absoluto': np.abs(y_true_array - y_pred)\n",
        "})\n"
      ],
      "metadata": {
        "id": "tRo0vdK9vywB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordena pelas maiores diferenças\n",
        "df_maiores_erros = df_erros.sort_values(by='Erro Absoluto', ascending=False)\n",
        "\n",
        "# Seleciona, por exemplo, os 10 piores casos\n",
        "top_erros = df_maiores_erros.head(100)\n"
      ],
      "metadata": {
        "id": "36Z3dd0FyoiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se X_test for DataFrame e tiver os mesmos índices\n",
        "if not isinstance(X_test, pd.DataFrame):\n",
        "    X_test_df = pd.DataFrame(X_test, columns=feature_names) # Use feature_names para nomes das colunas\n",
        "else:\n",
        "    X_test_df = X_test.copy() # Se já for DataFrame, apenas copie\n",
        "\n",
        "X_test_df.reset_index(drop=True, inplace=True)\n",
        "df_erros.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Concatena features com os erros\n",
        "df_completo = pd.concat([X_test_df, df_erros], axis=1)\n",
        "\n",
        "# Pega os 10 piores casos com todas as features\n",
        "top_casos_completos = df_completo.sort_values(by='Erro Absoluto', ascending=False).head(100)\n"
      ],
      "metadata": {
        "id": "IADshRdtyr_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ver os X_test com maiores erros\n",
        "top_casos_completos.head(100)"
      ],
      "metadata": {
        "id": "udKlvkjrzSxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "top_casos_completos[['Valor Real', 'Valor Predito']].plot(kind='bar', figsize=(12, 6))\n",
        "plt.title('Comparação entre Valor Real e Valor Predito (Top 10 Maiores Erros)')\n",
        "plt.xlabel('Casos com maior erro')\n",
        "plt.ylabel('Valor')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sHNzjx4Yy_xM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "\n",
        "# Carrega o pipeline treinado\n",
        "# res = joblib.load('/content/drive/MyDrive/Trabalho ML Mestrado 01-2025/full_results.pkl')\n",
        "pipeline = res['pipeline']\n",
        "feature_names = res.get('feature_names', None)\n",
        "\n",
        "# Extrai o DecisionTreeRegressor\n",
        "regressor = pipeline.named_steps['regressor']\n",
        "\n",
        "# Desenha a árvore\n",
        "plt.figure(figsize=(20, 10))\n",
        "tree.plot_tree(\n",
        "    regressor,\n",
        "    feature_names=feature_names,\n",
        "    filled=True,        # nós coloridos para melhor distinção\n",
        "    rounded=True,       # cantos arredondados\n",
        "    fontsize=10\n",
        ")\n",
        "plt.title(\"Visualização da Árvore de Decisão\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xEeuA3V94z6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se estiver usando Colab, pode ser necessário instalar o Graphviz no sistema:\n",
        "# !apt-get install -qq graphviz\n",
        "# !pip install -q graphviz\n",
        "\n",
        "import joblib\n",
        "import graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "# # 1) Carrega o pipeline treinado\n",
        "# res = joblib.load('/content/drive/MyDrive/Trabalho ML Mestrado 01-2025/full_results.pkl')\n",
        "# pipeline = res['pipeline']\n",
        "# feature_names = res.get('feature_names', None)\n",
        "\n",
        "# 2) Extrai o DecisionTreeRegressor\n",
        "regressor = pipeline.named_steps['regressor']\n",
        "\n",
        "# 3) Exporta para DOT\n",
        "dot_data = export_graphviz(\n",
        "    regressor,\n",
        "    out_file=None,\n",
        "    feature_names=feature_names,\n",
        "    filled=True,\n",
        "    rounded=True,\n",
        "    special_characters=True\n",
        ")\n",
        "\n",
        "# 4) Renderiza com graphviz e exibe inline\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph\n"
      ],
      "metadata": {
        "id": "gNI1ymrWOXG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variância nas Árvores de Decisão- EDITAR TUDO PARA REGREÇÃO\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "60j9N1m-gnf8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análise da Variação na Acurácia\n",
        "\n",
        "A propriedade de variância também implica em efeitos na variabilidade do desempenho dos modelos. Para fins de exemplo, podemos usar a acurácia como medida de desempenho através das funções do scikit-learn. Entretanto, outras métricas de desempenho como Recall e Precisão, que são mais indicadas para problemas em que o número de instâncias por classe é desbalanceado (como é o caso deste conjunto de dados) poderiam também ser exploradas (a critério do aluno, podem ser adicionadas para observação, mas a questão deve ser respondida com base na acurácia)."
      ],
      "metadata": {
        "id": "4dE3IWkdlpVP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código abaixo executa repetidas vezes o treinamento das árvores de decisão, da mesma forma que no item *Analisando a Estrutura das Árvores*.\n",
        "Modifique-o de forma a obter a acurácia para cada execução e então calcule a média, desvio padrão, máximo e mínimo dos valores. Use esses resultados para responder à **Questão 2**.\n",
        "\n",
        "**Atenção: Não mude os valores que estão sendo passados para os parâmetros random_state para garantir a reprodutibilidade do código**.\n"
      ],
      "metadata": {
        "id": "Dp5K0jyaLduN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análise de Instância individuais\n",
        "\n",
        "1. Treine novamente uma árvore de decisão usando um novo conjunto de treino gerado com a função train_test_split. Utilize 20% de dados de teste e, desta vez, não **especifique valor nenhum para o random_state**.\n",
        "\n",
        "2. Faça a predição para as instâncias especificadas abaixo e preencha na tabela do excel indicada no **Moodle** a classificação encontrada (0 para maligno e 1 para benigno).\n"
      ],
      "metadata": {
        "id": "OrsF5WMepURZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## O Efeito da Poda"
      ],
      "metadata": {
        "id": "AZelTK5blG_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As árvores de decisão treinadas nos itens anteriores não possuíam nenhuma forma de poda. No entanto, é possível utilizar técnicas de poda através do scikit-learn. Como consequência, elas podem ter uma complexidade além do que é necessário na modelagem do problema.\n",
        "\n"
      ],
      "metadata": {
        "id": "IYchPiY3lPMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo de Pré-poda: profundidade máxima da árvore\n",
        "Podemos especificar a profundidade máxima da árvore utilizando o parâmetro max_depth."
      ],
      "metadata": {
        "id": "rKvCQYSjovEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código abaixo gera árvores de decisão com diferentes profundidades máximas e as avalia em termos de acurácia.\n",
        "\n",
        "Observe que todas as árvores são treinadas e avaliadas com os mesmos conjuntos de treino e teste, visto que especificamos o parâmetro $random\\_state = 0$.\n",
        "\n",
        "Com base nesse código, e possíveis modificações que você faça a ele, responda à **Questão  4** do questionário.\n",
        "\n",
        "**Não mude o valor que está sendo passado em random_state=0**.\n"
      ],
      "metadata": {
        "id": "5bzmcFPutJR7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo de Pós-poda: Custo-complexidade\n",
        "\n",
        "A biblioteca scikit-learn possui uma implementação de pós-poda por custo-complexidade, baseada no parâmetro de custo-complexidade $\\alpha \\ge 0$.\n",
        "\n",
        "Na implementação descrita na biblioteca, é definido também um custo-complexidade efetivo do nodo. Quanto maior for a taxa de erros ao se podar a subárvore de um nodo, maior será seu custo-complexidade efetivo. Além disso, quanto maior for a complexidade (número de nodos terminais) da subárvore do nodo, menor será seu custo-complexidade efetivo.\n",
        "Em resumo, um nodo com alto custo-complexidade efetivo é um nodo importante para diminuir a taxa de erros e com baixa complexidade.\n",
        "\n",
        "Dentro da biblioteca, passamos um parâmetro $ccp\\_alpha$ que serve como um custo-complexidade efetivo de corte: subárvores são podadas enquanto houver nodos com custo-complexidade menor do que o parâmetro $ccp\\_alpha$.\n",
        "Ou seja, quando maior for o parâmetro, mais intensa será a poda.\n",
        "\n",
        "Para mais informações:\n",
        "* https://scikit-learn.org/stable/modules/tree.html#minimal-cost-complexity-pruning\n",
        "* https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html\n",
        "\n",
        "Use o código abaixo para resolver à **Questão 5**."
      ],
      "metadata": {
        "id": "3IHz5Y-KvrCI"
      }
    }
  ]
}